# ğŸ“ˆ Beating the S&P 500 â€” The Virtue of Transaction Costs (VoT)

Machine learning (ML) return forecasts often exhibit strong **gross** backtest performance.  
Yet in liquid large-cap universes such as the S&P 500, these gains frequently disappear **net of transaction costs**.  

This paper shows:

> **ML stock return forecasts remain economically valuable in active S&P 500 stocks â€” even net of realistic transaction costs â€” when the portfolio construction is properly disciplined.**

The key contribution is a *forecast-to-trade mapping* that filters out the noise from ML stock return predictions.

Main mechanism:

> Using predicted stock returns, optimising the portfolio **as if transaction costs are large** improves benchmark-relative performance.

Reason:

> Transaction costs enter as a quadratic penalty on active trades. This shrinks forecast-induced reallocations, prevents aggressive rebalancing, and reduces turnover.  
> By penalising noisy trades, transaction costs filter out spurious forecast variation and extract the small but persistent signal in ML return predictions.

In short, I use transaction costs as an economically grounded layer of regularisation on the portfolio construction This solves two problems at once: Return prediction noise is filtered out and transaction costs are accounted for.

---

## ğŸ’¡ Key Idea

Naive forecast are mapped to trades using ranks/deciles.

Problems:
- Ignore turnover
- Ignore liquidity
- Translate weak cross-sectional predicted return differences into aggressive reallocations
- Ignores transaction costs
- Collapse net of costs

### ğŸ› ï¸ The solution: Predictâ€“Thenâ€“Optimise

A modular two-stage pipeline:

### 1ï¸âƒ£ Predict (Forecast Returns)

One-month-ahead expected returns. Four machine learning algorithms are considered:

- **XGBoost (XGB)**
- **Transformer (TF)**
- **Instrumented Principal Component Analysis (IPCA)**
- **Random Fourier Features (RFF)**

Forecasting is **fully separated** from portfolio optimisation.

### 2ï¸âƒ£ Optimise (Cost-Aware Portfolio Construction)

Portfolio weights are chosen subject to:

- Long-only
- Fully invested
- Active S&P 500 constituents only
- Volatility benchmarking (market-like risk)
- Quadratic price-impact transaction costs
- Optional concentration limits

---

## ğŸ¯ Evaluation Setting (Deliberately Demanding)

| Dimension | Setting |
|------------|----------|
| Universe | Active S&P 500 constituents |
| Frequency | Monthly rebalancing |
| Sample | 2004â€“2024 |
| Benchmark | S&P 500 (SPY total return) |
| Performance | Net of transaction costs |
| Portfolio | Long Only & Fully Invested |

This avoids:

- Microcaps
- Illiquidity effects
- Leverage
- Shorting

---

## ğŸ† Main Result

> Optimising **as if transaction costs are large** improves benchmark-relative performance.

### âš™ï¸ Core Mechanism: The Virtue of Transaction Costs (VoT)

Transaction costs enter the objective as a quadratic penalty term.

- Costs scale with **trade sizeÂ²**
- Larger AUM â‡’ stronger penalty
- Acts like an **endogenous Ridge-like penalty on active trades**

Large transaction costs:
- Shrink active trades
- Thereby reducing overtrading
- Leading to higher Sharpe and Information ratios

Transaction costs become a **discipline mechanism**, not just an execution drag.

### ğŸ“Š Backtest Results (Net of Transaction Costs)

IPCA is the best performing algorithm. All results are fully out of sample.

| Portfolio | Î¼ | Ïƒ | Sharpe | TO | IR | MaxD | DCap | Î± |
|------------|------|------|--------|------|------|--------|------|------|
| **S&P 500** | 0.110 | 0.147 | 0.645 | â€¢ | 0.000 | -0.509 | 1.000 | 0.000 |
| **IPCA** | 0.142 | 0.158 | 0.802 | 0.054 | 0.512 | -0.473 | 0.973 | 0.031 |

Notes

- **Î¼**: Annualised mean return  
- **Ïƒ**: Annualised volatility  
- **Sharpe**: Annualised Sharpe ratio  
- **IR**: Annualised Information Ratio (vs. S&P 500)  
- **Î±**: Annualised abnormal return over the S&P 500  
- **TO**: Average monthly turnover  
- **MaxD**: Maximum drawdown  
- **DCap**: Drawdown capture ratio

IPCA delivers:

- Higher return than the S&P 500
- Similar volatility  
- Higher Sharpe ratio  
- Strong benchmark-relative performance (IR = 0.512)  
- Low turnover (5.4% per month)  
- High annualised alpha 


![Model Illustration](Fig.svg)

---

# ğŸ§® Portfolio Construction

## ğŸ§© Portfolio Choice Problem

Each month, a fund chooses portfolio weights according to:

$$
\begin{aligned}
\max_{\pi_t} \quad
& \hat{r}_{t+1}^\top \pi_t \\
&- w_t (\pi_t - G_{t-1}\pi_{t-1})^\top
\Lambda_t
(\pi_t - G_{t-1}\pi_{t-1})
\end{aligned}
$$

Subject to:

#### Long-Only and (optional) Concentration Limit

$$
0 \le \pi_t \le \pi_{\max}
$$

#### Fully Invested

$$
\mathbf{1}^\top \pi_t = 1
$$

#### Volatility Benchmarking

$$
\sqrt{\pi_t^\top \Sigma_t \pi_t} \le \sigma_t^B
$$


| Symbol | Meaning |
|--------|----------|
| $\pi_t$ | Portfolio weights |
| $\hat{r}_{t+1}$ | Predicted returns |
| $w_t$ | Fund's wealth (AUM) |
| $G_{t-1}$ | Drift adjustment matrix |
| $\Lambda_t$ | Price impact (Kyleâ€™s $\lambda$) |
| $\Sigma_t$ | Covariance matrix of stock returns |
| $\sigma_t^B$ | S&P500 volatility (EWMA estimate) |
| $\pi_{\max}$ | Concentration limit |

## ğŸ”§ Implementation Details

### Constraint Handling

- **Softmax parameterisation**
  - Ensures long-only
  - Ensures fully invested

- **ReLU penalties**
  - Max weight violations
  - Variance constraint violations

### Transaction Costs

- Quadratic impact (Kyle Î»)
- Costs applied to deviations from drifted baseline
- Scale with AUM

### Optimisation
Solve the portfolio choice problem numerically.

- PyTorch
- Gradient ascent (Adam)

---

## ğŸ§  Why This Works

Two layers of regularisation:

1. **ML shrinkage for return predictions** (early stopping / Ridge / tree regularisation)
2. **Transaction cost shrinkage for active trades** 

The second layer reduces aggressive trading based on noisy machine learning return predictions and successfully filters out the (small) predictive signal in these forecasts.

---

# ğŸ§© Signals Used

The predictive signals combine **accounting-based characteristics** and **market-based characteristics**, constructed from **Compustat** (fundamentals) and **CRSP** (prices and returns).

### ğŸ“Š Accounting-Based Signals  
Capture firm fundamentals such as:
- Profitability  
- Investment and asset growth  
- Accruals  
- Leverage and capital structure  
- Cash flow dynamics  

### ğŸ“ˆ Market-Based Signals  
Capture price-driven effects such as:
- Momentum (multiple horizons)  
- Volatility (idiosyncratic and total)  
- Liquidity and turnover  
- Beta and downside risk  

### â³ Information Timing & Look-Ahead Control

All signals are constructed to strictly avoid a look-ahead bias.

- Accounting information is assumed to become publicly available **four months after the fiscal period end**.
- Return forecasts use only information that would have been available to an investor at that time.

This ensures the backtests reflect a **realistic, implementable information set**.

---

# ğŸ“‚ Repository Structure

### ğŸ—‚ï¸ Data & Preprocessing

- `Data_Preprocessing.py`  
  Builds monthly signals dataset

- `Feature_Engineering.py`  
  Cross-sectional standardisation

- `SP500_Constituents.py`  
  Monthly investable universe

- `SPY_return.py`  
  Benchmark return series

- `Estimate Covariance Matrix.py`  
  Factor-based covariance estimation

---

### ğŸ¤– Return Forecasting

- `XGBoost.py`
- `Transformer.py`
- `IPCA.py`
- `RFF.py`

Each produces 1-month-ahead fully out of sample forecasted stock returns.

---

### ğŸ“Š Portfolio & Results

- `Portfolio_Optimiser.py`  
  Cost-aware constrained optimisation

- `Results.py`  
  Backtests, performance metrics, turnover, Sharpe, IR, drawdowns

- `General_Functions.py`  
  Shared utilities

---

# ğŸ“ Conceptual Contribution

This repository demonstrates:

- ML forecasts contain real information in large-cap equities.
- The bottleneck is not prediction.
- The bottleneck is **implementation discipline**.
- Transaction costs provide an economically grounded regularisation device.

---

# ğŸ Bottom Line

Transaction costs are not just friction.

They are a **regularisation tool** that converts ML forecasts into investable alpha in the S&P 500.
